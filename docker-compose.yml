services:
  ollama:
    image: ollama/ollama:latest
    container_name: ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
      # Apple Silicon GPU acceleration
      - METAL_DEVICE=on
      - METAL_DEVICE_INDEX=0
    volumes:
      - ollama_data:/root/.ollama
    ports:
      - "11434:11434"
    restart: unless-stopped

  hedge-fund:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  hedge-fund-reasoning:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA --show-reasoning
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  hedge-fund-ollama:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/main.py --ticker AAPL,MSFT,NVDA --ollama
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  backtester:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/backtester.py --ticker AAPL,MSFT,NVDA
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

  backtester-ollama:
    build: .
    image: ai-hedge-fund
    depends_on:
      - ollama
    volumes:
      - ./.env:/app/.env
    command: python src/backtester.py --ticker AAPL,MSFT,NVDA --ollama
    environment:
      - PYTHONUNBUFFERED=1
      - OLLAMA_BASE_URL=http://ollama:11434
    tty: true
    stdin_open: true

volumes:
  ollama_data: 